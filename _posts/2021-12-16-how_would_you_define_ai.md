# How would you define AI?

*from [Elements of AI Course](https://course.elementsofai.com/1/3)*

Let's first scrutinize the following definitions that have been proposed earlier:
* "cool things that computers can't do"
* machines imitating intelligent human behavior
* autonomous and adaptive systems

Which definition of AI do you like best? How would you define AI? 

My answer:

1. „cool things that computers can't do"
Obviously not a very scientific definition as already mentioned, therefore easy to remember but not very precise. It is based on several assumptions that are not defined. E.g. what is „cool“ ? This is a purely subjective measure.

And „things“ someone or something can do? Does this refer to doing theoretical activities, mathematical, philosophical? Or to producing an actual output like a product or self driving car?

And what are „computers“ in this definition? Google’s supercomputer, Smartphones, (Self-driving) cars, my Thermomix or the singing greetingscard, that has more computational capacity as all computers used by the Allies in 1945 (i translated this quote from Michio Kaku, die Physik der Zukunft).
So this definition is too wide and applies to too many issues to be actually useful.

2. machines imitating intelligent human behavior

I don’t like this definition neither. Besides the problem that I mentioned already in 1. - the lack of clear definitions of the used words (machines, very technical word, intelligent behaviour- to the second I will refer later more). I feel uncomfortable with the word „imitating“ in this definition. By imitating you assume that you copy a behaviour but not necessarily need to understand the basic underlying assumptions of why you do it.

You would technically just map the processes and then copy them. But you would not analyse why you need to do this exactly process or not. There is no deep understanding of the basic relations and causes.

However, as this behaviour has been our survival technique for our organisms for 3.5 billion years now (we copied the surviving behaviour techniques just by.. surviving - but clearly without understanding why). I would suggest that this definition describes in some kind artificial intelligence - but not in its full capacity.
For this I am missing some kind of hint how this machine learned and whether it can learn.

3. autonomous and adaptive systems

This is a more complete definition. „Systems“ refer to a wider understanding of working environments than „machines“ and is less of an ingenieural word. Systems can include neurosystems, ecosystems and lifts this definition from a purely ingenieurs view.
Autonomous and adaptive add the part that I was missing in 2. However, combined, this definition is just too wide to be applicable. Is an e.coli infection AI? According to this definition it may be. It acts autonomous and adapts to its environment, it is a system of virus cells. So I suppose, there is still missing something.

---> My definition:

In my opinion it is kind of backwards-thinking when we try to generate an AI definition while we haven’t even defined the „I“ part - the intelligence. So to say, I would not really separate into AI and „normal“ intelligence, but would rather set a step back and try to find a definition for intelligence that comprises also AI.

Intelligence in my view would be the sensing, understanding and acting with the environment - surely not even close to a strong definition, but I haven’t spent too much philosophical thinking on this issue yet, so this would suffice for the moment.

More important for me is the following: I am now not aware anymore in which book I read this thought, but I felt very comfortable with it: one of our theories could be that every part, every cell and every organism comprises some kind of intelligence, just in different capacities.

So to say I rather would create some kind of intelligence scala. Here in the low levels may be the definition „sensing, acting with environment,“ in the less lower something like „evaluating processed based on given criteria, computing, improving processes“ in the more higher „sensing an I, differentiating between my actions and environment, seeking better results from my actions“ and in even higher categories „developing curiosity to learn how and why processes affect each other, trying so emphatize with others, seeking ethical questions“.

Here I would not differentiate between AI and „normal“ I because it just puts the perspective on the creation and has some religious taste I don’t like. I would rather look at the actual possibilities of the actors (human, robots, cars, chatbots but also animals, ecosystems like forests, microbiotics) and set the marks and compare how much the capabilities differ from each other on the scale.
Then we could say something like „this A-intelligence level Chatbot is really dumb, it does not really answer the tricky questions and I still need to call the service center. But
my car has already achieved D-intelligence level and is now officially as clever as my dog“ :)
