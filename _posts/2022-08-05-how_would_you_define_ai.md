# How would you define AI?

![imageof a brain](https://user-images.githubusercontent.com/56920075/183062758-a9406329-6e2a-41c8-b9c4-d740d88a3ae1.png)


In the [Elements of AI Course](https://course.elementsofai.com/1/3) I encountered the following question: “How would you define AI?”, along with the three following commonly used definitions that were proposed for discussion: 
1.	"cool things that computers can't do"
2.	“machines imitating intelligent human behavior”
3.	“autonomous and adaptive systems”

I want now to discuss the proposed definitions and create my own understanding and definition of what AI really is. Let’s start with the first.
„cool things that computers can't do" Obviously not a very scientific definition, therefore easy to remember but not very precise. It is based on several assumptions that are not defined, for example. what is considered „cool“ ? This is a purely subjective measure.
And „things“ someone or something can do? Does this refer to doing mathematical computations, or philosophical inferences? Or does it relate to producing an actual output like a product or self-driving car?

Finally, what are „computers“ in this definition? Google’s supercomputer, Smartphones, (Self-driving) cars, a Thermomix, or a singing greetings card – which has more computational capacity than all computers used by the Allies in 1945 (quote from Michio Kaku, die Physik der Zukunft)? This definition is too general and applies to too many issues to be actually useful.

Let’s have a closer look at the second definition: “machines imitating intelligent human behavior”.
This definition doesn’t seem to fit either. Besides the problem that I mentioned already in the first definition discussion - the lack of clear definitions of the used words (e.g. what is meant by machines? What exactly is intelligent behavior?), I feel uncomfortable with the word „imitating“. By imitating you assume that you copy a behavior but do not necessarily need to understand the basic underlying assumptions of why you do it. You are missing the process of analyzing and understanding of why you need to replicate this exact behavior or maybe a different one. There is no deep understanding of the basic correlations and causes.
However, this behavior has been the survival technique for our organisms for 3.5 billion years now (we copied the surviving behavior techniques just by.. surviving - but clearly without understanding why). I would suggest that this definition describes some kind of intelligence - but is this “real” intelligence? Clearly, this could not mean it in its full capacity. So, I am still missing some kind of a hint of whether it can learn and how the learning process occurs.

Now let’s get to the last definition: “autonomous and adaptive systems”.
This is a more complete definition. „Systems“ refer to a wider understanding of working environments than „machines“ and is less of an “engineer-al” description. Systems can include also neuro systems or ecosystems and therefore has a wider application range. “Autonomous and adaptive” add the part that I was missing in the second definition. However, all in all, this definition is just too wide to be applicable. Is an e.coli infection also Artificial Intelligence? According to this definition, it may be. It acts autonomously and adapts to its environment, it is a system of virus cells. I suppose, there is still missing something.

After having looked at the proposed definitions, I would like to offer my own: 
In my opinion, it is kind of backward-thinking when we try to generate a definition for AI while haven’t even defined the „I: intelligence” part. Before looking at what “artificial” and “intelligence” might mean in a combination, why shouldn’t we first be clear about the meaning of the individual parts? Even more, in my opinion, it does not make sense to insert an artificial separation between “artificial” and „normal“ intelligence, but I would rather set a step back and try to find a definition for intelligence that comprises also AI.
So, what is intelligence?

Intelligence in my view would include “sensing, understanding, and acting with the environment” - surely not even close to a strong definition, but I could (and certainly will) dedicate a full blog post to this later on. For the moment, this definition seems sufficient for the purpose.
Once I read in a book (sorry, I don’t remember which one), that one adequate conception would be that every cell and every organism comprises some kind of intelligence, it just varies in the amount of “capacity” of how much intelligence it possesses.

Based on this, we could view intelligence as a kind of scalable unit. Like a glass, which could be empty, or more or less full in a continuous range of fill levels (and we could even distinguish of what kind of liquid is in the glass). So on our intelligence “scala”, the low levels may represent something like the definition „sensing and acting with the environment,“; in the less low levels there may be something like „evaluating processes based on given criteria, computing, and improving processes“; in the higher levels you would find „sensing an I, differentiating between my actions and environment, seeking better results from my actions“; and in the (so far) highest categories there will be something like „developing curiosity to learn how and why processes influence each other, trying to emphasize with others, seeking ethical questions“. 

The continuous scala has the benefit that it does not claim to have a single fit-for-all intelligence definition and it also does not produce categories, where things have to “fit”. Also it can be extended, based on our needs and future discoveries (for example, if we encounter some “super”-intelligence, we could just expand the range). <sub> Note: I was writing this actually before I discovered, that there is a very structured and well written essay by [Tim Urban](https://waitbutwhy.com/2015/01/artificial-intelligence-revolution-2.html=) on this topic. /2022-08-23 </sub>

Furthermore, with an intelligence scala, we no longer have the need to differentiate between “artificial” and „normal“ (and either way, I do not like this differentiation, because it puts too much focus on the perspective of creation and has some religious taste). We could easily just look at the outcome, the actual capabilities of the agents or systems (like humans, robots, cars, chatbots but also animals, ecosystems like forests, and bacterial organisms). We could put them on the scale, based on their level of intelligence and even measure, how much distance there is between certain actors, i.e. how much the capabilities are different from each other. We could easily map, how much “AI” has progressed and how “far” it is from human intelligence (or, maybe in the future vice versa). 

Imagine you saying „this one-digit-intelligence level Chatbot is really dumb, it does not really answer the tricky questions, and I still need to call the service center. But my car has already achieved a double-digit-intelligence level and is now officially as clever as my dog“.
